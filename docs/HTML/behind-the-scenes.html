<!DOCTYPE html>
<html>
<head>
  <title>Should You Drop Out?</title>
  <style>
    /* Global styles */
    body {
      font-family: Arial, sans-serif;
      line-height: 1.5;
      margin: 0;
      padding: 0;
      background-color: #fff;
      color: #333;
    }

    .container {
      max-width: 960px;
      margin: 0 auto;
      padding: 20px;
    }

    h1, h2, h3 {
      margin-top: 0;
    }

    a {
      color: #007bff;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

        /* Header */
        header {
          position: relative;
        }

        .banner-overlay {
          background-image: url('51955360542_f3ebf62e95_o.jpg');
          background-size: cover;
          background-position: center;
          background-repeat: no-repeat; /* Prevent repeating the background image */
          height: 200px;
          width: 100%;
          text-align: center;
          position: relative;
          display: flex;
          align-items: center;
          justify-content: center;
        }

        .banner-overlay::before {
          content: "";
          position: absolute;
          top: 0;
          left: 0;
          width: 100%;
          height: 100%;
          background-color: rgba(0, 0, 0, 0.5);
        }

        .header-content {
          display: flex;
          flex-direction: column;
          align-items: center;
          justify-content: center;
          color: #fff;
          height: 100%;
        }

        .banner-title {
          margin: 0;
          font-size: 32px;
          font-weight: bold;
          margin-top: 0px;
          margin-bottom: 0px; /* Adjust the margin-bottom value to reduce the space */
          filter: brightness(1.2); /* Increase brightness */
        }

        header .logo {
          height: 90px;
          margin-bottom: 100px; /* Adjust the margin-bottom value to reduce the space */
          filter: brightness(1.2); /* Increase brightness */
        }

        /* Navigation */
        nav ul {
          list-style-type: none;
          margin: 0;
          padding: 0;
          text-align: center;
          background-color: hwb(0 0% 100% / 0.91); /* Change to match the banner overlay */
          border-bottom: 1px solid #ccc;
        }


        nav ul li {
          display: inline;
          margin: 0 10px;
        }

        nav ul li a {
          display: inline-block;
          padding: 10px;
          color: #fff; /* Change to match the banner title color */
          font-weight: bold;
          text-transform: uppercase;
          transition: color 0.3s;
        }

        nav ul li a:hover {
          color: #e6e6e6; /* Change to a slightly lighter shade for hover effect */
          background-color: rgba(101, 66, 66, 0.1); /* Add a hover background color */
        }


        /* Main content */
        main {
          background-color: #fff; /* Remove the background color */
          padding: 20px;
          margin-top: 20px;
          box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
          border: none; /* Remove the border */
        }

        section {
          margin-bottom: 40px;
        }

        section img {
          max-width: 100%;
          margin-bottom: 20px;
        }

        /* Footer */
        footer {
          background-color: rgba(0, 0, 0, 0.836); /* Add a hover background color */
          color: #fff;
          padding: 10px;
          text-align: center;
          margin-top: 20px;
        }
        footer p {
          margin-bottom: 0px; /* Increase the margin-bottom value to lower the text */
        }

        footer .logo {
          height: 90px;
          filter: brightness(1.2);
          margin-bottom: 20px; /* Add margin to separate the logo from the text */
        }

        footer a {
          color: #fff;
          margin: 0 5px;
        }

        footer a:hover {
          text-decoration: underline;
        }
  </style>
</head>
<body>
  <header>
    <div class="banner-overlay">
      <div class="header-content">
        <h1 class="banner-title">Should You Drop Out?</h1>
      </div>
    </div>
  </header>  

  <nav>
    <ul>
      <li><a href="project-description.html">Project Description</a></li>
      <li><a href="data.html">Data</a></li>     
      <li><a href="behind-the-scenes.html">Behind the Scenes</a></li>
      <li><a href="analysis.html">Analysis & Results</a></li>
      <li><a href="results.html">Implications</a></li>
      <li><a href="authors.html">Authors</a></li>
      <li><a href="references.html">References</a></li>
    </ul>
  </nav>

  <main class="container">
    <section>
      <h2>Unveiling the Reliability of Our Research and Methods</h2>
      <p>Welcome to the fascinating world behind the scenes of our research endeavor. In this section, we delve into the code-intensive aspects that underpin the reliability of our findings and methodologies. Our team of authors, committed to ensuring a diversity of ideas and perspectives, has diligently divided the tasks involved. This meticulous approach guarantees a comprehensive exploration, free from any biases that may hinder the integrity of our research.</p>
      <span style="font-style: italic; color: #999999;">The <a href="https://github.com/leomassoc/LSE-DS105L-Data-Detectives/tree/main/notebooks">notebooks</a> of our repository has been organised in order to provide different aspects and steps in our research and do not necessarily reflect the order of neither this page nor the analysis one.</span>
    </section>  
      <h3>1) Data Collection: Unveiling the Building Blocks</h3>
      <section>
        <p>Our main and initial source was the <a href="https://www.census.gov/"> Census.gov </a> API, a treasure trove of comprehensive data capturing various variables that illuminate the intricacies of US society. To kick-start our research, we accessed the API's JSON file using the provided API Key. This invaluable resource furnished us with crucial information on the percentage of educational attainment and the number of educational firms across different counties. </p>
        <section>
          <code style="display: block; padding: 10px; background-color: #f2f2f2; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
            <span style="color: #008000">#Setting up the API Query parameters for the educational services industry</span>
            <span style="color: #0000ff">params1</span> = {<span style="color: #a31515">"NAICS2017"</span>: <span style="color: #800080">61</span>}
            <br><br>
            <span style="color: #008000">#Requesting the json file from the census website using the api key</span>
            <span style="color: #0000ff">url</span> = <span style="color: #a31515">"https://api.census.gov/data/2017/ecnbasic?get=NAICS2017_LABEL,NAICS2017,GEO_ID,FIRM&for=county:*&key={}".format(api_key)</span>
            <span style="color: #0000ff">response</span> = <span style="color: #0000ff">requests</span>.<span style="color: #0000ff">request</span>(<span style="color: #a31515">"GET"</span>, <span style="color: #0000ff">url</span>, <span style="color: #0000ff">params</span>=<span style="color: #0000ff">params1</span>)
          </code>
        </section>
        

        
        <p>To streamline our analysis, we converted the obtained data into a Pandas data frame, facilitating a more organized and user-friendly format.</p>
        <p>In addition to the Census.gov API, we incorporated other valuable sources available in CSV or Excel formats. Leveraging the versatility of the Pandas library, we seamlessly imported and processed these files for further examination.</p>
        <section>
          <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
            <span style="color: #0000ff">import</span> pandas <span style="color: #0000ff">as</span> pd
            <br>
            <span style="color: #008000">#import excel file and convert to dataframe</span>
            us_gdp = pd.<span style="color: #0000ff">read_excel</span>(<span style="color: #a31515">"../data/us_gdp_2009-18.xlsx"</span>)
            <br><br>
            <span style="color: #008000"># if GeoFIPS is under 10000, add a 0 in front of it</span>
            us_gdp[<span style="color: #a31515">'Clean GeoFIPS'</span>] = us_gdp[<span style="color: #a31515">'Clean GeoFIPS'</span>].<span style="color: #0000ff">apply</span>(<span style="color: #0000ff">lambda</span> x: '<span style="color: #a31515">{0:0>5}</span>'.<span style="color: #0000ff">format</span>(x))
            <br><br>
            <span style="color: #008000">#convert GeoFIPS to string</span>
            us_gdp[<span style="color: #a31515">'Clean GeoFIPS'</span>] = us_gdp[<span style="color: #a31515">'Clean GeoFIPS'</span>].<span style="color: #0000ff">astype</span>(<span style="color: #a31515">'string'</span>)
            <br><br>
            <span style="color: #008000">#keep only Clean GEOFIPS and GDP per Capita 2017</span>
            us_gdp = us_gdp[[<span style="color: #a31515">'Clean GeoFIPS'</span>, <span style="color: #a31515">'GDP per Capita 2017'</span>]]
            <br><br>
            <span style="color: #008000">#rename Clean GeoFIPS to GEO_ID</span>
            us_gdp = us_gdp.<span style="color: #0000ff">rename</span>(<span style="color: #0000ff">columns</span>=<span style="color: #0000ff">{'Clean GeoFIPS': 'GEO_ID'}</span>)
            <br><br>
            us_gdp.<span style="color: #0000ff">head</span>(5)
          </code>
        </section>
        

      </section>    
      <h3>2) Data Cleaning: Shaping the Foundation</h3>
      <p>To establish a solid foundation for our analysis, we undertook meticulous data cleaning procedures. We pruned unnecessary columns, focusing solely on California's data for our initial exploration. The following steps outline our data cleaning process for the American Community Survey (ACS) survey database:
      </p>
      <section>
        <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
          <span style="color: #008000">#Merging the two datasets</span>
          merged_census = pd.<span style="color: #0000ff">merge</span>(df_educationservices, df_perc_bach, on='county')
          <br><br>
          <span style="color: #008000">#drop state_y column and rename state_x to state</span>
          merged_census = merged_census.drop(columns=['state_y', 'NAICS2017'])
          merged_census = merged_census.rename(columns={'state_x': 'state', 'FIRM':'Number of Educational Institutions','DP02_0064PE':'Percent of Population with a Bachelor\'s Degree'})
          <br><br>
          <span style="color: #008000">#Convert the columns to the correct data types</span>
          merged_census['Percent of Population with a Bachelor\'s Degree'] = merged_census['Percent of Population with a Bachelor\'s Degree'].astype(float)
          merged_census['county'] = merged_census['county'].astype(int)
          <br><br>
          <span style="color: #008000"># The last two columns are currently unneeded but will be later used for contextual analysis.</span>
          <br>
          <span style="color: #008000">#Drop the last two columns</span>
          merged_census = merged_census.drop(columns=['DP02_0088PE', 'DP02_0123PE'])
          merged_census.<span style="color: #0000ff">head</span>()
        </code>
      </section>
       
    
      <p>In our quest to merge datasets seamlessly, we harmonized the variable types from the ECS Census Database. This critical step ensured compatibility and facilitated the subsequent merging with the Bureau of Economic data.</p>
      
      <h3>3) Data Merging: Forging Connections</h3>
      <p>By fusing the economic and American Community Survey Census datasets, we ventured into a realm of interconnected insights. Our primary focus was California, and to ensure consistency and minimize conflicting data, we meticulously selected the year 2017 for both census sources.</p>
      <section>
        <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
          <span style="color: #008000">#Merging the two datasets</span>
          merged_census = pd.<span style="color: #0000ff">merge</span>(df_california1, df_california2, on='county')
          <br><br>
          <span style="color: #008000">#drop state_y column and rename state_x to state</span>
          merged_census = merged_census.drop(columns=['state_y', 'NAICS2017'])
          merged_census = merged_census.rename(columns={'state_x': 'state', 'FIRM':'Number of Educational Institutions','DP02_0064PE':'Percent of Population with a Bachelor\'s Degree'})
          <br><br>
          <span style="color: #008000">#Convert the columns to the correct data types</span>
          merged_census['Percent of Population with a Bachelor\'s Degree'] = merged_census['Percent of Population with a Bachelor\'s Degree'].astype(float)
          merged_census['county'] = merged_census['county'].astype(int)
          <br><br>
          <span style="color: #008000"># The last two columns are currently unneeded but will be later used for contextual analysis.</span>
          <br>
          <span style="color: #008000">#Drop the last two columns</span>
          merged_census = merged_census.drop(columns=['DP02_0088PE', 'DP02_0123PE'])
        </code>
      </section>      
      <p>Navigating Obstacles: Overcoming County Discrepancies
        During the merging process, we encountered certain challenges. The ECS dataset encompassed more counties (48) compared to the ACS dataset (40) for the state of California. Despite this discrepancy, our resourcefulness allowed us to extract meaningful trends and patterns within California's available county sample.</p>
      
      <h3>4) Transforming our Data: Unleashing the Power of Integration</h3>
      <p>Realizing the existence of two similar county identification codes, GEO_ID and GEO_FIPS, within US government data, we harmonized our merged census data frame. Specifically, we modified the GEO_FIPS column to match the GEO_ID data, opening new avenues for further analysis.</p>
      <section>
        <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
          <span style="color: #008000">#Create a copy of merged_census called education_data</span>
          education_data = merged_census.<span style="color: #0000ff">copy</span>()
          <br><br>
          <span style="color: #008000">#Working on the GEO_ID column: keep only the code after 0500000US</span>
          education_data['GEO_ID'] = education_data['GEO_ID'].str.<span style="color: #0000ff">split</span>('US').str[1]
          education_data.<span style="color: #0000ff">head</span>()
        </code>
      </section>      
      <p>Creating a Comprehensive Landscape: County-level Insights
        Harnessing the potential of the GEO_ID column, we successfully integrated another dataset containing National Income from 2009 to 2018 per county. This integration enabled us to enrich our pandas data frame with essential information on educational institutions and the percentage of individuals holding a Bachelor's degree across each county. </p>
        <section>
          <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
            <span style="color: #008000">#Merge the gdp dataframe with the education_data dataframe</span>
            gdp_and_census = pd.<span style="color: #0000ff">merge</span>(education_data, us_gdp, on='GEO_ID')
            gdp_and_census.<span style="color: #0000ff">head</span>(20)
          </code>
        </section>        

      <h3>5) Data Visualization: Unveiling Patterns and Trends</h3>
      <p>Visualization played a pivotal role in our quest to unravel hidden relationships between education and salary. Utilizing scatter plots, we effortlessly identified potential trends and patterns, enabling a more intuitive understanding of the data.</p>
      <p> With <a href="https://github.com/leomassoc/LSE-DS105L-Data-Detectives/blob/1bb90d2974ce89b07b19217100f7fc7b760c96df/notebooks/NB5%20County%20Level%20Analysis.ipynb"> Notebook 5 </a>, we crafted scatter plots depicting the GDP per Capita versus the Percent of Population with a Bachelor's degree for all US states. This comprehensive visual exploration allowed us to identify key insights across the nation. The accompanying code snippet showcases the process behind generating these enlightening visualizations.</p>
      <section>
        <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
          <span style="color: #008000"># Import required libraries</span><br>
          <span style="color: #0000ff">import</span> pandas <span style="color: #0000ff">as</span> pd<br>
          <span style="color: #0000ff">from</span> plotnine <span style="color: #0000ff">import</span> ggplot, aes, geom_point, labs, theme, element_text, element_rect<br>
          <br>
          <span style="color: #008000"># Define desired values</span><br>
          desired_values = range(1, 51)<br>
          <br>
          <span style="color: #008000"># Initialize correlation data dictionary</span><br>
          correlation_data = {'State': [], 'Correlation Coefficient': []}<br>
          <br>
          <span style="color: #008000"># Loop through each desired value</span><br>
          <span style="color: #0000ff">for</span> desired_value <span style="color: #0000ff">in</span> desired_values:<br>
              &nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #008000"># Filter the data based on the condition</span><br>
              &nbsp;&nbsp;&nbsp;&nbsp;filtered_data = df[df['state'] == desired_value]<br>
              <br>
              &nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #0000ff">if</span> <span style="color: #0000ff">not</span> filtered_data.empty:<br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #008000"># Calculate the correlation coefficient</span><br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;correlation_coefficient = filtered_data["Percent of Population with a Bachelor's Degree"].corr(filtered_data["GDP per Capita 2017"])<br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;correlation_text = f"Correlation: {correlation_coefficient:.2f}"<br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;correlation_data['State'].append(desired_value)<br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;correlation_data['Correlation Coefficient'].append(correlation_coefficient)<br>
                  <br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #008000"># Create and customize the plot</span><br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plot = (ggplot(filtered_data, aes(x="Percent of Population with a Bachelor's Degree", y="GDP per Capita 2017")) +<br>
                      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;geom_point() +<br>
                      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;labs(x="Percent of Population with a Bachelor's Degree", y="GDP per Capita 2017", title=correlation_text)) + \<br>
                      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;theme(text=element_text(family='DejaVu Sans',<br>
                                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size=9, color='black', face='italic'),<br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;axis_title=element_text(face='bold'),<br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;axis_text=element_text(face='italic'),<br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plot_title=element_text(face='bold',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size=12)) + \<br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;theme(panel_border=element_rect(linewidth=0.5, color='black', fill=None))<br>
              <br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #008000"># Display the plot</span><br>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(plot)<br>
        </code>
      </section>
      
      
      <p><strong>Unveiling the Pinnacle: Counties of Distinction</strong></p>
        Further analysis involved identifying the counties with the highest GDP per Capita and Percent of Population with a Bachelor's degree. Our sorting process yielded two distinct data frames, each comprising the top 25 counties for these respective variables. The updated scatterplot code incorporated county labels, accentuating their origin within the corresponding US state. </p>
        <section>
          <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
            <span style="color: #008000"># Sort the DataFrame based on "Percent of Population with a Bachelor's Degree" in descending order</span><br>
            df_sorted = df.sort_values("Percent of Population with a Bachelor's Degree", ascending=False)<br>
            df_sorted2 = df.sort_values("GDP per Capita 2017", ascending=False)<br>
            <br>
            <span style="color: #008000"># Get the top 25 rows based on the sorted DataFrame</span><br>
            top_25 = df_sorted.head(25)<br>
            <br>
            <span style="color: #008000"># Plot the scatter plot with labels and size scaling</span><br>
            plot = (ggplot(df, aes(x="Percent of Population with a Bachelor's Degree", y="GDP per Capita 2017")) +<br>
                    geom_point(alpha=0.3) +<br>
                    scale_size(range=[2, 10]) +<br>
                    geom_text(aes(label='state'), size=5.5, data=top_25, nudge_y=6) +<br>
                    geom_text(aes(label='state'), size=5.5, data=top_25_2, nudge_x=0, nudge_y=labs(x="Percent of Population with a Bachelor's Degree", y="GDP per Capita 2017", size="Number of Educational Institutions", title="All US Counties")) +<br>
                    theme(text=element_text(family="Dejavu Sans", size=9, color='black', face='italic'),<br>
                          axis_title=element_text(face='bold'),<br>
                          axis_text=element_text(face='italic'),<br>
                          plot_title=element_text(face='bold', size=12)) +<br>
                    scale_x_continuous(limits=(0, 100)) +<br>
                    theme(panel_border=element_rect(linewidth=0.5, color='black', fill=None))<br>
                   )<br>
            <br>
            <span style="color: #008000"># Print the plot with adjusted coordinate limits</span><br>
            print(plot + coord_cartesian(xlim=(2, 40), ylim=(4, 200)))<br>
          </code>
        </section>
        
      <p>In <a href="https://github.com/leomassoc/LSE-DS105L-Data-Detectives/blob/1bb90d2974ce89b07b19217100f7fc7b760c96df/notebooks/NB5%20County%20Level%20Analysis.ipynb">Notebook 5 </a> we also found the states with counties that were amongst the highest GDP per Capita’s and Education Attainment. Below, the ‘common_values’ set is used to store these states and eliminate duplicates. It is then converted to a list, and the states extrapolated from their numbers using the data frame created in <a href="https://github.com/leomassoc/LSE-DS105L-Data-Detectives/blob/1bb90d2974ce89b07b19217100f7fc7b760c96df/notebooks/NB2%20Creation%20of%20a%20final%20Data%20Frame.ipynb"> Notebook 2 </a> .</p>
      <section>
        <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
          <span style="color: #008000"># Find common values in the 'state' column of the top 25 rows</span><br>
          common_values = set()<br>
          <br>
          <span style="color: #008000"># Iterate over each value in the 'state' column</span><br>
          for value in top_25['state']:<br>
              <span style="margin-left: 4em;">if value in top_25['state'].values:</span><br>
                  <span style="margin-left: 8em;">common_values.add(value)</span><br>
          <br>
          <span style="color: #008000"># Convert the set to a list</span><br>
          common_values = list(common_values)<br>
          <br>
          common_values
        </code>
      </section>
      
      <section>
        <h3>6) Forecasting: Peering into the Future</h3>
        <p>In <a href="https://github.com/leomassoc/LSE-DS105L-Data-Detectives/blob/main/notebooks/NB3%20Forecasting.ipynb"> Notebook 3</a>, our primary focus revolves around forecasting education and GDP trends. To conduct this analysis, we utilized comprehensive historical data sets that effectively captured the past situation in the United States. The economic data was sourced from the World Bank, while the college percentage figures were obtained from a .xlsx file provided by Census.gov. We diligently processed and visualized the data, taking particular care to ensure accurate units of measurement were maintained.</p>
       <p>
        In the case of GDP, the levels ranged from 200,000 to 600,000, while the college percentages varied from 5 to 40. Upon thorough analysis, we immediately observed a positive trend present in both variables. To generate accurate forecasts, we employed the "Prophet" library, which automatically generates forecasts within a specified time frame. The resulting graph showcases the forecasted values, along with upper and lower error margins.
       </p>
       <p>Before proceeding with the forecasting process, we meticulously prepared the data frame to meet the library's requirements. This involved renaming the date column as "ds" after converting it to a date-time format, and designating the variable of interest as "y." These preparatory steps ensured seamless integration with the forecasting library and facilitated accurate predictions.</p>
       <section>
        <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
          <span style="color: #008000"># In the GDP data keep only year and GDP per capita (constant 2015 US$) and rename these as DS and Y respectively</span><br>
          gdp_us_time = gdp_us_time[['Year', 'GDP per capita (constant 2015 US$)']]<br>
          gdp_us_time.columns = ['ds', 'y']<br>
          <br>
          <span style="color: #008000"># Transform the DS column into datetime format</span><br>
          gdp_us_time['ds'] = pd.to_datetime(gdp_us_time['ds'], format='%Y')<br>
          <br>
          gdp_us_time.head()<br>
        </code>
      </section>      
        <p><strong>Illuminating the Pandemic:</strong> Highlighting a Historic Event
          Recognizing the profound impact of the COVID-19 pandemic, we incorporated a visual element to underscore its effects on education and the economy. By plotting a prominent line representing the year 2020, we drew attention to this unprecedented event and its repercussions on the observed trends.</p>
          <section>
            <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
              <span style="color: #008000"># Plot the forecast with the labels year and GDP per capita (constant 2015 US$)</span><br>
              fig1 = m.plot(gdp_forecast)<br>
              ax = fig1.gca()<br>
              ax.set_xlabel('Year')<br>
              ax.set_ylabel('US GDP per capita (constant 2015 US$)')<br>
              <br>
              <span style="color: #008000"># Add a line on 2020 with a legend</span><br>
              plt.axvline(x='2020-01-01', color='red', linestyle='--')<br>
              plt.text('2020-01-01', 50000, '2020', rotation=270)<br>
              plt.show()<br>
            </code>
          </section>
          
        <p><strong>Synthesizing the Journey: </strong>A Cohesive Narrative
          To consolidate our findings, we merged the two forecasts, weaving together a comprehensive visual narrative. This final merged plot provided a panoramic view of the projected educational and economic landscape.</p>
          <section>
            <code style="display: block; padding: 10px; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.5; margin: 0 auto; max-width: 800px;">
              <span style="color: #008000"># Plot the two forecasts together</span><br>
              fig, ax1 = plt.subplots()<br>
              ax1.plot(gdp_forecast['ds'], gdp_forecast['yhat'], color='red')<br>
              ax1.set_xlabel('Year')<br>
              ax1.set_ylabel('GDP per capita (constant 2015 US$)', color='red')<br>
              ax1.tick_params('y', colors='red')<br>
              ax2 = ax1.twinx()<br>
              ax2.plot(ed_forecast['ds'], ed_forecast['yhat'], color='blue')<br>
              ax2.set_ylabel('College Percentage', color='blue')<br>
              ax2.tick_params('y', colors='blue')<br>
              fig.tight_layout()<br>
              <br>
              <span style="color: #008000"># Add a line to denote the year 2023 and write 2023 next to it</span><br>
              plt.axvline(x='2023-01-01', color='black', linestyle='--')<br>
              plt.text('2023-01-01', 15, '2023', rotation=270)<br>
              plt.show()<br>
            </code>
          </section>          
        <p>Embarking on this research journey allowed us to uncover valuable insights into the intricate relationship between education and economic indicators. Through meticulous data collection, cleaning, merging, and visualization, we unraveled hidden patterns and forecasted future trends. Our commitment to rigorous methodologies and open exploration shines through each step, ensuring the reliability and robustness of our findings.
        </p>

      <h3>7) Unleashing the Web: Alua's Journey of Learning HTML and CSS</h1>

      <p>As a student at the prestigious London School of Economics, my passion for Economics has driven me to explore the vast realms of data science. Amidst this journey, I encountered a unique opportunity to delve into website design using HTML and CSS. Opting for the road less traveled, I embraced the challenge of learning HTML coding to create captivating web pages. In this analysis, I will recount my learning journey, discussing the challenges I faced, the implications of mastering HTML and CSS, and my plans to leverage this newfound knowledge.</p>
      <p>Starting out, I was well-aware of the alternative route: utilizing Markdown to construct websites. However, I felt an undeniable curiosity to explore the intricacies of HTML and CSS, despite knowing it would be an arduous undertaking. Armed with determination, I embarked on my HTML and CSS odyssey.</p>
      <p>Learning HTML and CSS presented its fair share of challenges, pushing me to think creatively and problem-solve. Some notable hurdles I encountered included:</p>
      <ol>
        <li>Syntax Mastery: The fundamental syntax of HTML and CSS was entirely new to me, demanding an understanding of tags, attributes, and selectors. Navigating through the labyrinth of opening and closing tags required precision and attention to detail.</li>
        <li>Design Consistency: Achieving a visually appealing and consistent design across various web pages proved to be challenging. Understanding the box model, positioning elements, and employing effective layouts required meticulousness and an eye for detail.</li>
        <li>Responsive Design: Crafting websites that adapt seamlessly to different devices and screen sizes introduced the concept of responsive design. Learning about media queries and implementing flexible layouts became essential skills in this mobile-driven era.</li>
        <li>Cross-Browser Compatibility: Ensuring a consistent user experience across different web browsers posed a significant challenge. Addressing browser-specific quirks and optimizing website performance required extensive testing and debugging.</li>
      </ol>
      <p>Mastering HTML and CSS holds immense implications, both academically and professionally:</p>
      <ul>
        <li>Enhanced Digital Communication: With the ability to create visually compelling web pages, I can effectively convey complex economic concepts and data-driven insights to a wider audience. This facilitates better digital communication and knowledge dissemination.</li>
        <li>Professional Opportunities: Proficiency in website design opens doors to various career opportunities. The intersection of data science, economics, and web design equips me with a unique skill set valued in industries such as fintech, e-commerce, and digital marketing.</li>
        <li>Improved User Experience: By implementing user-centered design principles and creating intuitive interfaces, I can enhance the user experience of websites, making them more engaging and accessible. This skill is vital in today's digital landscape, where user satisfaction drives success.</li>
      </ul>
      <p>Armed with a solid foundation in HTML and CSS, I plan to leverage this knowledge in multiple ways:</p>
      <ol>
        <li>Academic Projects: I will employ HTML and CSS to enhance the presentation of my academic projects and research findings. This will allow me to present data-driven insights in a visually compelling manner, improving the effectiveness of my work.</li>
        <li>Personal Portfolio: Building a personal website will serve as a platform to showcase my academic achievements, skills, and projects. By applying responsive design and creative layout techniques, I can leave a lasting impression on potential employers and collaborators.</li>
        <li>Collaborative Projects: Collaborating with fellow students and professionals, I can contribute to the design and development of websites, bridging the gap between data-driven insights and user experience. This multidisciplinary approach will foster innovation and generate impactful solutions.</li>
      </ol>
      <p>My journey of learning HTML and CSS has been both challenging and rewarding. Overcoming the hurdles, I have acquired a powerful set of skills that will enable me to communicate complex economic ideas effectively, unlock new career opportunities, and create engaging user experiences. With a solid foundation in HTML and CSS, I am excited to embark on academic projects, build my personal portfolio, and collaborate on impactful ventures. The fusion of data science, economics, and web design has equipped me with a unique skill set that will undoubtedly shape my future endeavors. As I leverage this newfound knowledge, I am eager to explore the endless possibilities and make a meaningful impact in the digital realm.</p>
      
      <section>
        <h3>8) Key Issues and Challenges</h3>
        <ol style="margin-left: 20px;">
          <li>Diversity in Educational Attainment Across Counties</li>
            <ol type="a">
              <li>While analyzing data from the Census Bureau, we discovered variations in the percentages of educational attainment among different counties.</li>
              <li>To address this issue, we developed a methodology to handle cases where multiple rows contained the same county and state code. We calculated the average percentage and consolidated the information into a single row.</li>
            </ol>
          <li>Data Discrepancies and Their Interpretation</li>
            <ol type="a">
              <li>During our analysis, we observed a significant reduction in the number of rows when transitioning from one dataset to another.</li>
              <li>While this may initially appear problematic, it is worth considering that it may reflect the reality that certain counties lack educational institutions.</li>
              <li>As a result, our research focuses on 1393 counties, instead of the original count of 3143, as we deemed the available data to be reliable and representative.</li>
            </ol>
        </ol>      
      </section>
  
    </main>
    <footer>
      <p style="margin-top: 30px;">2023 Data Detectives</p>
      <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/LSE_Logo.svg/638px-LSE_Logo.svg.png?20110331145302" alt="Logo" class="logo" style="max-width: 25px; height: auto;">
    </footer>  
</body>
</html>